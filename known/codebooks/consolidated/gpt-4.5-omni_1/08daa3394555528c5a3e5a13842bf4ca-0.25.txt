You are an expert in thematic analysis. You are giving labels and definitions for qualitative codes.
Each code includes one or more concepts and definitions. Each code is independent of another. Never attempt to merge them.
For each code, reflect on the logical relationship between the concepts.
Then, write a combined sentence of criteria covering all the concepts. Use clear and generalizable language and do not introduce unnecessary details. 
Finally, write an accurate verb phrase to best represent the code.
The research question is: In the context of NetLogo learning and practice: What perceptions - strengths, weaknesses, and adoption plans - do interviewees perceive LLM-driven interfaces? How do they use it to support their work? What are their needs for LLM-based interfaces?
Always follow the output format:
---
Definitions for each code (9 in total):
1.
Concepts: {Repeat the input 1}
Relationship: {What is logical relationship between concepts in code 1, or N/A if not applicable}
Criteria: {Who did what, and how for code 1}
Phrase: {The most representative verb phrase for the concepts}
...
9. 
Concepts: {Repeat the input 9}
Relationship: {What is logical relationship between concepts in code 9, or N/A if not applicable}
Criteria: {Who did what, and how for code 9}
Phrase: {The most representative verb phrase for the concepts}
---
~~~
1.
Concepts: warning against blind reliance on ai, importance of user expertise
- Users warn against blindly following AI without understanding.
- User emphasizes the need for expertise to effectively use AI and avoid blindly following its suggestions.

2.
Concepts: ai hallucination, discussing ai hallucinations
- User notes that AI might hallucinate functions or details.
- Users discuss instances where AI generates incorrect or non-existent information.

3.
Concepts: expresses frustration, recounts an experience of ai generating non-existent functions
- User expresses frustration with AI hallucinating functions that do not exist.
- Recounting experiences of AI generating non-existent functions.

4.
Concepts: model library, model search expectation
- User expects AI to retrieve specific models from a library but finds it does not due to potential miscommunication.
- User expects AI to find specific models but is disappointed when it does not.

5.
Concepts: ai direction issues, ai can limit options & points to different sometimes wrong directions
- User notes that AI's direction can be problematic for novices.
- AI's ability to infer needs and provide direction, sometimes inaccurately.

6.
Concepts: misinterpretation, misleading information
- User discusses the potential for AI to misinterpret or misunderstand tasks, leading to incorrect outputs.
- The interviewee points out that AI can sometimes provide misleading or incorrect information.

7.
Concepts: ai understanding issues, human-ai understanding differences
- User notes discrepancies in AI's understanding of specific models.
- User notes the difference between human and AI in understanding specific tasks.

8.
Concepts: ai response reflection, noting inconsistency in ai output, evaluating ai output
- Users reflect on the non-deterministic nature of AI responses.
- Users note and observe inconsistency and variability in AI's output, making it unpredictable.
- User regularly evaluates AI outputs and notes the non-deterministic nature of responses.

9.
Concepts: capability doubts, questioning ai's feature capabilities
- Doubting the AI's capability to perform certain tasks.
- Users express uncertainty about AI's capabilities, questioning and showing initial confusion over its functions.
===
---
Definitions for each code (9 in total):
1.
Concepts: warning against blind reliance on ai, importance of user expertise
Relationship: Both concepts emphasize the need for user awareness and understanding when using AI.
Criteria: Users warn against blindly following AI without understanding and emphasize the need for expertise to effectively use AI.
Phrase: Cautioning against blind reliance on AI

2.
Concepts: ai hallucination, discussing ai hallucinations
Relationship: Both concepts involve the occurrence and discussion of AI generating incorrect or non-existent information.
Criteria: Users note that AI might hallucinate functions or details and discuss instances where AI generates incorrect or non-existent information.
Phrase: Discussing AI hallucinations

3.
Concepts: expresses frustration, recounts an experience of ai generating non-existent functions
Relationship: Both concepts involve user frustration and specific experiences with AI generating non-existent functions.
Criteria: Users express frustration with AI hallucinating functions and recount experiences of AI generating non-existent functions.
Phrase: Expressing frustration over AI hallucinations

4.
Concepts: model library, model search expectation
Relationship: Both concepts involve user expectations regarding AI's ability to retrieve specific models from a library.
Criteria: Users expect AI to retrieve specific models from a library but are disappointed when it does not due to potential miscommunication.
Phrase: Experiencing unmet model search expectations

5.
Concepts: ai direction issues, ai can limit options & points to different sometimes wrong directions
Relationship: Both concepts involve AI providing problematic or inaccurate directions.
Criteria: Users note that AI's direction can be problematic for novices and that AI can limit options and point to different, sometimes wrong, directions.
Phrase: Noting AI direction issues

6.
Concepts: misinterpretation, misleading information
Relationship: Both concepts involve AI providing incorrect or misleading information due to misinterpretation.
Criteria: Users discuss the potential for AI to misinterpret tasks, leading to incorrect outputs, and point out that AI can sometimes provide misleading information.
Phrase: Discussing AI misinterpretation and misleading information

7.
Concepts: ai understanding issues, human-ai understanding differences
Relationship: Both concepts involve discrepancies between human and AI understanding of tasks.
Criteria: Users note discrepancies in AI's understanding of specific models and the difference between human and AI understanding of specific tasks.
Phrase: Noting human-AI understanding differences

8.
Concepts: ai response reflection, noting inconsistency in ai output, evaluating ai output
Relationship: All concepts involve users reflecting on and evaluating the inconsistency and variability in AI outputs.
Criteria: Users reflect on the non-deterministic nature of AI responses, note inconsistency and variability in AI's output, and regularly evaluate AI outputs.
Phrase: Reflecting on AI output inconsistency

9.
Concepts: capability doubts, questioning ai's feature capabilities
Relationship: Both concepts involve users expressing uncertainty and questioning AI's capabilities.
Criteria: Users doubt the AI's capability to perform certain tasks and express uncertainty about its functions.
Phrase: Questioning AI's capabilities
---