You are an expert in thematic analysis. You are giving labels and definitions for qualitative codes.
Each code includes one or more concepts and definitions. Each code is independent of another. Never attempt to merge them.
For each code, reflect on the logical relationship between the concepts.
Then, write a combined sentence of criteria covering all the concepts. Use clear and generalizable language and do not introduce unnecessary details. 
Finally, write an accurate verb phrase to best represent the code.
The research question is: In the context of NetLogo learning and practice: What perceptions - strengths, weaknesses, and adoption plans - do interviewees perceive LLM-driven interfaces? How do they use it to support their work? What are their needs for LLM-based interfaces?
Always follow the output format:
---
Definitions for each code (4 in total):
1.
Concepts: {Repeat the input 1}
Relationship: {What is logical relationship between concepts in code 1, or N/A if not applicable}
Criteria: {Who did what, and how for code 1}
Phrase: {The most representative verb phrase for the concepts}
...
4. 
Concepts: {Repeat the input 4}
Relationship: {What is logical relationship between concepts in code 4, or N/A if not applicable}
Criteria: {Who did what, and how for code 4}
Phrase: {The most representative verb phrase for the concepts}
---
~~~
1.
Concepts: advocate for human-ai collaboration and collective problem-solving, suggest collaborative ai and advocate for collaborative learning
- Participants advocate for human-AI collaboration and emphasize collective problem-solving.
- Participants suggest collaborative AI systems and advocate for collaborative knowledge sharing and generation through AI.

2.
Concepts: valuing responsive feedback, preferring ai over delayed responses
- Participants value collaborative and immediate feedback from AI-driven interfaces in supporting their workflow.
- Participants prefer immediate feedback from AI over delayed responses from listservs.

3.
Concepts: appreciate ai-generated code quality, appreciating ai assistance and automatic integration
- Participants appreciate AI performance, code quality, annotation ability, code documentation, and code organization, and recognize value in AI-generated code.
- Participants appreciate AI assistance in coding and the benefits of integrating AI-generated code into their work.

4.
Concepts: critiquing ai response options, critiquing ai responses
- Critiques AI response options and suggests improvements
- The interviewee evaluates AI responses and decides not to use certain features or extensions based on that evaluation.
===
Here are the definitions for each code:

---
1.
Concepts: advocate for human-ai collaboration and collective problem-solving, suggest collaborative ai and advocate for collaborative learning
Relationship: The concepts are logically related as they all emphasize the importance of collaboration and collective problem-solving in the context of human-AI interaction.
Criteria: Participants advocate for and suggest collaborative approaches to learning and problem-solving with AI.
Phrase: Advocating for collaborative AI integration.

2.
Concepts: valuing responsive feedback, preferring ai over delayed responses
Relationship: The concepts are logically related as they both highlight the importance of timely feedback in the workflow.
Criteria: Participants value and prefer immediate feedback from AI-driven interfaces over delayed responses.
Phrase: Preferring immediate AI feedback.

3.
Concepts: appreciate ai-generated code quality, appreciating ai assistance and automatic integration
Relationship: The concepts are logically related as they both emphasize the benefits of AI-generated code in terms of quality and integration.
Criteria: Participants appreciate the quality and benefits of AI-generated code and its integration into their work.
Phrase: Appreciating AI-generated code benefits.

4.
Concepts: critiquing ai response options, critiquing ai responses
Relationship: The concepts are logically related as they both involve evaluating and improving AI responses.
Criteria: Participants critique and evaluate AI responses and options, suggesting improvements.
Phrase: Critiquing AI responses.