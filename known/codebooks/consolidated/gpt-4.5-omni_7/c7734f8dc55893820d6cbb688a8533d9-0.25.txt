You are an expert in thematic analysis. You are giving labels and definitions for qualitative codes.
Each code includes one or more concepts and definitions. Each code is independent of another. Never attempt to merge them.
For each code, reflect on the logical relationship between the concepts.
Then, write a combined sentence of criteria covering all the concepts. Use clear and generalizable language and do not introduce unnecessary details. 
Finally, write an accurate verb phrase to best represent the code.
The research question is: In the context of NetLogo learning and practice: What perceptions - strengths, weaknesses, and adoption plans - do interviewees perceive LLM-driven interfaces? How do they use it to support their work? What are their needs for LLM-based interfaces?
Always follow the output format:
---
Definitions for each code (3 in total):
1.
Concepts: {Repeat the input 1}
Relationship: {What is logical relationship between concepts in code 1, or N/A if not applicable}
Criteria: {Who did what, and how for code 1}
Phrase: {The most representative verb phrase for the concepts}
...
3. 
Concepts: {Repeat the input 3}
Relationship: {What is logical relationship between concepts in code 3, or N/A if not applicable}
Criteria: {Who did what, and how for code 3}
Phrase: {The most representative verb phrase for the concepts}
---
~~~
1.
Concepts: considers optimal input terms, ensuring clarity in ai interaction
- User considers the optimal terms to use when inputting requests to AI.
- Users dictate parameter fields and engage in dialogue with AI to refine requests and clarify requirements for accurate responses.

2.
Concepts: ai understanding discrepancies, noting ai output variability
- Notes discrepancies in AI's understanding and search results.
- Users note the variability and lack of consistency in AI's output, reflecting on its misunderstandings and non-deterministic responses.

3.
Concepts: warning against blind reliance on ai, emphasizing the need for debugging expertise
- Users warn against the risks of blindly following AI without sufficient expertise and caution about AI's potential to generate incorrect functions.
- Users emphasize the need for expertise to understand and debug AI-generated errors, cautioning against blindly following AI.
===
---
Definitions for each code (3 in total):
1.
Concepts: considers optimal input terms, ensuring clarity in ai interaction
Relationship: Users engage in dialogue with AI to refine and clarify requests.
Criteria: Users consider the optimal terms to use when inputting requests to AI, dictating parameter fields and engaging in dialogue to ensure clarity and accurate responses.
Phrase: Refining AI interaction terms

2.
Concepts: ai understanding discrepancies, noting ai output variability
Relationship: Users reflect on AI's misunderstandings and non-deterministic responses.
Criteria: Users note discrepancies in AI's understanding and the variability in its output, reflecting on its inconsistencies and misunderstandings.
Phrase: Observing AI output variability

3.
Concepts: warning against blind reliance on ai, emphasizing the need for debugging expertise
Relationship: Users caution against blind reliance on AI and emphasize the need for debugging expertise.
Criteria: Users warn against the risks of blindly following AI without sufficient expertise and emphasize the need for expertise to understand and debug AI-generated errors.
Phrase: Cautioning against blind AI reliance
---